import { useCallback, useRef, useEffect } from 'react';
import { useTTSStore } from '../store/ttsStore';
import { tarotApiService } from '../services/apiService';

export interface UseTTSOptions {
  onComplete?: () => void;
  onError?: (error: string) => void;
  autoPlay?: boolean; // ì˜¤ë””ì˜¤ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ì‹œ ìë™ ì¬ìƒ ì—¬ë¶€
}

// Base64 ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ArrayBufferë¡œ ë³€í™˜
const parseAudioChunk = (base64Data: string): ArrayBuffer | null => {
  try {
    const binaryString = atob(base64Data);
    const bytes = new Uint8Array(binaryString.length);
    for (let i = 0; i < binaryString.length; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
  } catch (error) {
    return null;
  }
};

// ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ì¬ìƒì„ ìœ„í•œ Web Audio API í´ë˜ìŠ¤
class TTSStreamingAudioPlayer {
  private audioContext: AudioContext | null = null;
  private isInitialized = false;
  private isPlaying = false;
  private nextStartTime = 0;
  private audioSources: AudioBufferSourceNode[] = [];
  private onPlaybackComplete?: () => void;
  private onPlaybackStart?: () => void;

  async initialize(): Promise<void> {
    if (this.isInitialized) return;

    try {
      // AudioContext ìƒì„±
      this.audioContext = new (window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();

      // iOS Safariì—ì„œëŠ” ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í›„ resume í•„ìš”
      if (this.audioContext.state === 'suspended') {
        await this.audioContext.resume();
      }

      this.isInitialized = true;
    } catch (error) {
      throw error;
    }
  }

  setCallbacks(onStart?: () => void, onComplete?: () => void) {
    this.onPlaybackStart = onStart;
    this.onPlaybackComplete = onComplete;
  }

  async addAndPlayChunk(arrayBuffer: ArrayBuffer): Promise<void> {
    if (!this.audioContext) {
      await this.initialize();
    }

    if (!this.audioContext) return;

    try {
      // ArrayBufferë¥¼ AudioBufferë¡œ ë””ì½”ë”©
      const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer.slice(0));

      // ì²« ë²ˆì§¸ ì²­í¬ì¸ ê²½ìš° ì¬ìƒ ì‹œì‘
      if (!this.isPlaying) {
        this.isPlaying = true;
        this.nextStartTime = this.audioContext.currentTime;
        this.onPlaybackStart?.();
      }

      // AudioBufferSourceNode ìƒì„± ë° ìŠ¤ì¼€ì¤„ë§
      const source = this.audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(this.audioContext.destination);

      // í˜„ì¬ ì‹œê°„ ë˜ëŠ” ì´ì „ ì²­í¬ ì¢…ë£Œ ì‹œì ì— ì¬ìƒ ì‹œì‘
      const startTime = Math.max(this.audioContext.currentTime, this.nextStartTime);
      source.start(startTime);

      // ë‹¤ìŒ ì²­í¬ì˜ ì‹œì‘ ì‹œê°„ ê³„ì‚°
      this.nextStartTime = startTime + audioBuffer.duration;

      // ì†ŒìŠ¤ ì¶”ì ì„ ìœ„í•´ ë°°ì—´ì— ì¶”ê°€
      this.audioSources.push(source);

      // ì¬ìƒ ì™„ë£Œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
      source.onended = () => {
        // ë§ˆì§€ë§‰ ì²­í¬ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì•½ê°„ì˜ ì§€ì—° í›„ ì²´í¬
        setTimeout(() => {
          const currentTime = this.audioContext!.currentTime;
          const hasMorePending = this.audioSources.some(src =>
            src !== source && src.buffer && currentTime < (src as any).startTime + src.buffer.duration
          );

          if (!hasMorePending && currentTime >= this.nextStartTime - 0.1) {
            // ëª¨ë“  ì¬ìƒì´ ì™„ë£Œë¨
            this.isPlaying = false;
            this.onPlaybackComplete?.();
          }
        }, 100);
      };

    } catch (error) {
      // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨ ë¬´ì‹œ
    }
  }

  stop(): void {
    this.audioSources.forEach(source => {
      try {
        source.stop();
      } catch (e) {
        // ì´ë¯¸ ì •ì§€ëœ ì†ŒìŠ¤ëŠ” ë¬´ì‹œ
      }
    });
    this.audioSources = [];
    this.isPlaying = false;
    this.nextStartTime = 0;
  }

  reset(): void {
    this.stop();
  }

  get hasAudio(): boolean {
    return this.audioSources.length > 0 || this.isPlaying;
  }

  get isCurrentlyPlaying(): boolean {
    return this.isPlaying;
  }
}

export const useTTS = (options: UseTTSOptions = {}) => {
  const { onComplete, onError, autoPlay = false } = options;
  const audioPlayerRef = useRef<TTSStreamingAudioPlayer>(new TTSStreamingAudioPlayer());

  const {
    status,
    error,
    progress,
    isPlaying,
    hasAudioData,
    isMuted,
    setStatus,
    setError,
    setProgress,
    setIsPlaying,
    setHasAudioData,
    reset
  } = useTTSStore();

  // SSE ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ TTS ìš”ì²­
  const requestTTSStream = useCallback(async (text: string, voice: string = 'nova', instructions?: string) => {
    if (isMuted) {
      console.log('ğŸ”‡ TTS is muted, skipping request');
      return;
    }

    if (status === 'loading') {
      console.log('âŒ Already loading, skipping request');
      return;
    }

    if (!text.trim()) {
      const errorMsg = 'í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”';
      setError(errorMsg);
      onError?.(errorMsg);
      return;
    }

    // ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ ì´ˆê¸°í™” ë° ë¦¬ì…‹
    audioPlayerRef.current.reset();

    // ì¬ìƒ ì½œë°± ì„¤ì •
    audioPlayerRef.current.setCallbacks(
      () => {
        // ì¬ìƒ ì‹œì‘ ì½œë°±
        setStatus('playing');
        setIsPlaying(true);
      },
      () => {
        // ì¬ìƒ ì™„ë£Œ ì½œë°±
        setStatus('idle');
        setIsPlaying(false);
        onComplete?.();
      }
    );

    setStatus('loading');
    setError(null);
    setProgress(0);
    setHasAudioData(false);

    try {
      const response = await tarotApiService.requestTTSStream(text, voice, instructions);

      if (!response.body) {
        throw new Error('Response bodyê°€ ì—†ìŠµë‹ˆë‹¤');
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();

        if (done) {
          setProgress(100);
          if (!autoPlay && hasAudioData) {
            setStatus('idle');
          }
          break;
        }

        // SSE ë°ì´í„° íŒŒì‹±
        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          if (line.startsWith('data:')) {
            const data = line.slice(5).trim();

            if (data === '[DONE]') {
              setProgress(100);
              if (!autoPlay && hasAudioData) {
                setStatus('idle');
              }
              return;
            }

            try {
              const eventData = JSON.parse(data);

              if (eventData.type === 'error') {
                throw new Error(eventData.error);
              } else if (eventData.type === 'speech.audio.delta' && eventData.audio) {
                const audioData = parseAudioChunk(eventData.audio);
                if (audioData) {
                  if (autoPlay) {
                    await audioPlayerRef.current.addAndPlayChunk(audioData);
                  }

                  if (!hasAudioData) {
                    setHasAudioData(true);
                  }
                }
              } else if (eventData.type === 'speech.audio.done') {
                setProgress(100);
                if (!autoPlay && hasAudioData) {
                  setStatus('idle');
                }
                return;
              }

            } catch (parseError) {
              // JSON íŒŒì‹± ì—ëŸ¬ ë¬´ì‹œ
            }
          }
        }

        // ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ì„ì˜)
        const currentProgress = progress;
        setProgress(Math.min(currentProgress + 10, 90));
      }

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : 'TTS ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤';
      setError(errorMsg);
      setStatus('error');
      onError?.(errorMsg);
    }
  }, [isMuted, status, setStatus, setError, setProgress, progress, autoPlay, setHasAudioData, onComplete, onError]);

  // ì˜¤ë””ì˜¤ ì œì–´ í•¨ìˆ˜ë“¤
  const playAudio = useCallback(async () => {
    // TODO: ìˆ˜ë™ ì¬ìƒì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ë¡œì§ êµ¬í˜„ í•„ìš”
  }, []);

  const stopAudio = useCallback(() => {
    audioPlayerRef.current.stop();
    setStatus('idle');
    setIsPlaying(false);
  }, [setStatus, setIsPlaying]);

  const resetAudio = useCallback(() => {
    audioPlayerRef.current.reset();
    setHasAudioData(false);
    reset();
  }, [reset, setHasAudioData]);

  // ìŒì†Œê±° ìƒíƒœ ë³€í™” ê°ì§€í•˜ì—¬ ì‹¤ì œ ì˜¤ë””ì˜¤ ì¤‘ì§€
  useEffect(() => {
    if (isMuted && isPlaying) {
      audioPlayerRef.current.stop();
    }
  }, [isMuted, isPlaying]);

  return {
    // ìƒíƒœ
    status,
    error,
    progress,
    isPlaying,
    hasAudioData,
    isMuted,

    // ì•¡ì…˜
    requestTTSStream,
    playAudio,
    stopAudio,
    reset: resetAudio,

    // ìœ í‹¸ë¦¬í‹°
    isLoading: status === 'loading',
    hasError: status === 'error',
    hasAudio: audioPlayerRef.current?.hasAudio ?? false,
    canPlay: hasAudioData && !isPlaying && status !== 'loading' && status !== 'error',
  };
};